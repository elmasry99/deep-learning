{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af18d62-4364-420b-bebd-a12c37cc8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81669c17-483f-4fa5-9278-410e3ec0f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b02f43e3-afa2-4ccd-acf7-1213dfabe9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedEfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ModifiedEfficientNet, self).__init__()\n",
    "        # Load pretrained EfficientNetB0\n",
    "        efficientnet = torchvision.models.efficientnet_b0(pretrained=True)\n",
    "        \n",
    "        # Keep all layers except the classifier\n",
    "        self.features = efficientnet.features\n",
    "        \n",
    "        # Freeze the feature layers\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Create new classifier layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(1280, 256),  # EfficientNetB0 outputs 1280 features\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.mean([2, 3])  # Global average pooling\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d2006fa-e5cc-48d5-a6bb-8831115b9adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data\\train_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 182040794/182040794 [02:38<00:00, 1151403.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./data\\test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 64275384/64275384 [00:58<00:00, 1092610.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the SVHN dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # EfficientNet expects 224x224 images\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.SVHN(\n",
    "    root='./data', \n",
    "    split='train',\n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.SVHN(\n",
    "    root='./data', \n",
    "    split='test',\n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0a951e-c8ea-4929-b910-7dd52ab30a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Besose\\anaconda3\\envs\\tf\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Besose\\anaconda3\\envs\\tf\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to C:\\Users\\Besose/.cache\\torch\\hub\\checkpoints\\efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 20.5M/20.5M [00:21<00:00, 1.02MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = ModifiedEfficientNet(num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f7bd092-e8b8-480b-9f84-e2ee5f80d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model():\n",
    "    print(\"Starting training...\")\n",
    "    model.train()\n",
    "    total_step = len(train_loader)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], '\n",
    "                      f'Loss: {loss.item():.4f}, '\n",
    "                      f'Accuracy: {100 * correct / total:.2f}%')\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] completed. '\n",
    "              f'Average Loss: {running_loss/total_step:.4f}, '\n",
    "              f'Final Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64637b97-5da4-4f2b-9e7f-660407b145bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model():\n",
    "    print(\"\\nEvaluating model on test set...\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f5de6b8-baef-4158-ae25-22e12df52cbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch [1/10], Step [50/2290], Loss: 2.1807, Accuracy: 20.69%\n",
      "Epoch [1/10], Step [100/2290], Loss: 1.9471, Accuracy: 24.75%\n",
      "Epoch [1/10], Step [150/2290], Loss: 2.0606, Accuracy: 27.17%\n",
      "Epoch [1/10], Step [200/2290], Loss: 1.8680, Accuracy: 28.45%\n",
      "Epoch [1/10], Step [250/2290], Loss: 1.9592, Accuracy: 29.73%\n",
      "Epoch [1/10], Step [300/2290], Loss: 1.8616, Accuracy: 30.64%\n",
      "Epoch [1/10], Step [350/2290], Loss: 1.7266, Accuracy: 31.43%\n",
      "Epoch [1/10], Step [400/2290], Loss: 1.7373, Accuracy: 32.05%\n",
      "Epoch [1/10], Step [450/2290], Loss: 1.7073, Accuracy: 32.90%\n",
      "Epoch [1/10], Step [500/2290], Loss: 1.7073, Accuracy: 33.59%\n",
      "Epoch [1/10], Step [550/2290], Loss: 1.6128, Accuracy: 34.18%\n",
      "Epoch [1/10], Step [600/2290], Loss: 1.7264, Accuracy: 34.45%\n",
      "Epoch [1/10], Step [650/2290], Loss: 1.6300, Accuracy: 34.88%\n",
      "Epoch [1/10], Step [700/2290], Loss: 1.7877, Accuracy: 35.28%\n",
      "Epoch [1/10], Step [750/2290], Loss: 1.7426, Accuracy: 35.45%\n",
      "Epoch [1/10], Step [800/2290], Loss: 1.8578, Accuracy: 35.66%\n",
      "Epoch [1/10], Step [850/2290], Loss: 1.6643, Accuracy: 35.93%\n",
      "Epoch [1/10], Step [900/2290], Loss: 1.9998, Accuracy: 36.13%\n",
      "Epoch [1/10], Step [950/2290], Loss: 1.5360, Accuracy: 36.28%\n",
      "Epoch [1/10], Step [1000/2290], Loss: 1.6767, Accuracy: 36.55%\n",
      "Epoch [1/10], Step [1050/2290], Loss: 1.6290, Accuracy: 36.72%\n",
      "Epoch [1/10], Step [1100/2290], Loss: 1.6010, Accuracy: 36.96%\n",
      "Epoch [1/10], Step [1150/2290], Loss: 1.5903, Accuracy: 37.22%\n",
      "Epoch [1/10], Step [1200/2290], Loss: 1.7143, Accuracy: 37.33%\n",
      "Epoch [1/10], Step [1250/2290], Loss: 1.6676, Accuracy: 37.48%\n",
      "Epoch [1/10], Step [1300/2290], Loss: 1.9009, Accuracy: 37.69%\n",
      "Epoch [1/10], Step [1350/2290], Loss: 1.6296, Accuracy: 37.81%\n",
      "Epoch [1/10], Step [1400/2290], Loss: 1.6130, Accuracy: 37.88%\n",
      "Epoch [1/10], Step [1450/2290], Loss: 1.8510, Accuracy: 38.04%\n",
      "Epoch [1/10], Step [1500/2290], Loss: 1.7717, Accuracy: 38.11%\n",
      "Epoch [1/10], Step [1550/2290], Loss: 1.7443, Accuracy: 38.22%\n",
      "Epoch [1/10], Step [1600/2290], Loss: 1.7532, Accuracy: 38.39%\n",
      "Epoch [1/10], Step [1650/2290], Loss: 1.4587, Accuracy: 38.44%\n",
      "Epoch [1/10], Step [1700/2290], Loss: 1.8212, Accuracy: 38.58%\n",
      "Epoch [1/10], Step [1750/2290], Loss: 1.5661, Accuracy: 38.69%\n",
      "Epoch [1/10], Step [1800/2290], Loss: 1.6555, Accuracy: 38.79%\n",
      "Epoch [1/10], Step [1850/2290], Loss: 1.8566, Accuracy: 38.92%\n",
      "Epoch [1/10], Step [1900/2290], Loss: 1.5983, Accuracy: 39.04%\n",
      "Epoch [1/10], Step [1950/2290], Loss: 1.5437, Accuracy: 39.12%\n",
      "Epoch [1/10], Step [2000/2290], Loss: 1.9260, Accuracy: 39.20%\n",
      "Epoch [1/10], Step [2050/2290], Loss: 1.6488, Accuracy: 39.26%\n",
      "Epoch [1/10], Step [2100/2290], Loss: 1.5423, Accuracy: 39.37%\n",
      "Epoch [1/10], Step [2150/2290], Loss: 1.4385, Accuracy: 39.46%\n",
      "Epoch [1/10], Step [2200/2290], Loss: 1.3073, Accuracy: 39.55%\n",
      "Epoch [1/10], Step [2250/2290], Loss: 1.7220, Accuracy: 39.57%\n",
      "Epoch [1/10] completed. Average Loss: 1.7259, Final Accuracy: 39.65%\n",
      "Epoch [2/10], Step [50/2290], Loss: 1.7998, Accuracy: 44.25%\n",
      "Epoch [2/10], Step [100/2290], Loss: 1.5128, Accuracy: 43.62%\n",
      "Epoch [2/10], Step [150/2290], Loss: 1.6050, Accuracy: 43.79%\n",
      "Epoch [2/10], Step [200/2290], Loss: 1.3685, Accuracy: 43.73%\n",
      "Epoch [2/10], Step [250/2290], Loss: 1.5168, Accuracy: 44.12%\n",
      "Epoch [2/10], Step [300/2290], Loss: 1.2659, Accuracy: 44.12%\n",
      "Epoch [2/10], Step [350/2290], Loss: 1.5829, Accuracy: 43.96%\n",
      "Epoch [2/10], Step [400/2290], Loss: 1.4491, Accuracy: 44.27%\n",
      "Epoch [2/10], Step [450/2290], Loss: 1.4137, Accuracy: 44.21%\n",
      "Epoch [2/10], Step [500/2290], Loss: 1.9126, Accuracy: 44.24%\n",
      "Epoch [2/10], Step [550/2290], Loss: 1.8735, Accuracy: 44.31%\n",
      "Epoch [2/10], Step [600/2290], Loss: 1.4984, Accuracy: 44.31%\n",
      "Epoch [2/10], Step [650/2290], Loss: 1.7403, Accuracy: 44.34%\n",
      "Epoch [2/10], Step [700/2290], Loss: 1.3892, Accuracy: 44.34%\n",
      "Epoch [2/10], Step [750/2290], Loss: 1.6476, Accuracy: 44.21%\n",
      "Epoch [2/10], Step [800/2290], Loss: 1.7954, Accuracy: 44.18%\n",
      "Epoch [2/10], Step [850/2290], Loss: 1.7246, Accuracy: 44.16%\n",
      "Epoch [2/10], Step [900/2290], Loss: 1.5057, Accuracy: 44.19%\n",
      "Epoch [2/10], Step [950/2290], Loss: 1.5064, Accuracy: 44.20%\n",
      "Epoch [2/10], Step [1000/2290], Loss: 1.7075, Accuracy: 44.22%\n",
      "Epoch [2/10], Step [1050/2290], Loss: 1.5902, Accuracy: 44.27%\n",
      "Epoch [2/10], Step [1100/2290], Loss: 1.7027, Accuracy: 44.30%\n",
      "Epoch [2/10], Step [1150/2290], Loss: 1.4118, Accuracy: 44.28%\n",
      "Epoch [2/10], Step [1200/2290], Loss: 1.0614, Accuracy: 44.39%\n",
      "Epoch [2/10], Step [1250/2290], Loss: 1.5523, Accuracy: 44.42%\n",
      "Epoch [2/10], Step [1300/2290], Loss: 1.4743, Accuracy: 44.50%\n",
      "Epoch [2/10], Step [1350/2290], Loss: 1.7234, Accuracy: 44.50%\n",
      "Epoch [2/10], Step [1400/2290], Loss: 1.6121, Accuracy: 44.54%\n",
      "Epoch [2/10], Step [1450/2290], Loss: 1.5438, Accuracy: 44.48%\n",
      "Epoch [2/10], Step [1500/2290], Loss: 1.5897, Accuracy: 44.54%\n",
      "Epoch [2/10], Step [1550/2290], Loss: 1.5049, Accuracy: 44.57%\n",
      "Epoch [2/10], Step [1600/2290], Loss: 1.5003, Accuracy: 44.62%\n",
      "Epoch [2/10], Step [1650/2290], Loss: 1.4047, Accuracy: 44.59%\n",
      "Epoch [2/10], Step [1700/2290], Loss: 1.4188, Accuracy: 44.68%\n",
      "Epoch [2/10], Step [1750/2290], Loss: 1.4795, Accuracy: 44.69%\n",
      "Epoch [2/10], Step [1800/2290], Loss: 1.5257, Accuracy: 44.69%\n",
      "Epoch [2/10], Step [1850/2290], Loss: 1.5637, Accuracy: 44.73%\n",
      "Epoch [2/10], Step [1900/2290], Loss: 1.8005, Accuracy: 44.81%\n",
      "Epoch [2/10], Step [1950/2290], Loss: 1.6075, Accuracy: 44.83%\n",
      "Epoch [2/10], Step [2000/2290], Loss: 1.3593, Accuracy: 44.82%\n",
      "Epoch [2/10], Step [2050/2290], Loss: 1.5015, Accuracy: 44.83%\n",
      "Epoch [2/10], Step [2100/2290], Loss: 1.5661, Accuracy: 44.94%\n",
      "Epoch [2/10], Step [2150/2290], Loss: 1.3716, Accuracy: 44.98%\n",
      "Epoch [2/10], Step [2200/2290], Loss: 1.5898, Accuracy: 44.99%\n",
      "Epoch [2/10], Step [2250/2290], Loss: 1.6440, Accuracy: 45.03%\n",
      "Epoch [2/10] completed. Average Loss: 1.5843, Final Accuracy: 45.06%\n",
      "Epoch [3/10], Step [50/2290], Loss: 1.5816, Accuracy: 45.50%\n",
      "Epoch [3/10], Step [100/2290], Loss: 1.3555, Accuracy: 46.94%\n",
      "Epoch [3/10], Step [150/2290], Loss: 1.7019, Accuracy: 46.27%\n",
      "Epoch [3/10], Step [200/2290], Loss: 1.5417, Accuracy: 46.67%\n",
      "Epoch [3/10], Step [250/2290], Loss: 1.4065, Accuracy: 46.24%\n",
      "Epoch [3/10], Step [300/2290], Loss: 1.3331, Accuracy: 46.48%\n",
      "Epoch [3/10], Step [350/2290], Loss: 1.1544, Accuracy: 46.71%\n",
      "Epoch [3/10], Step [400/2290], Loss: 1.3312, Accuracy: 46.77%\n",
      "Epoch [3/10], Step [450/2290], Loss: 1.1515, Accuracy: 46.81%\n",
      "Epoch [3/10], Step [500/2290], Loss: 1.6993, Accuracy: 46.92%\n",
      "Epoch [3/10], Step [550/2290], Loss: 1.4764, Accuracy: 46.74%\n",
      "Epoch [3/10], Step [600/2290], Loss: 1.4866, Accuracy: 46.78%\n",
      "Epoch [3/10], Step [650/2290], Loss: 1.4542, Accuracy: 46.66%\n",
      "Epoch [3/10], Step [700/2290], Loss: 1.9233, Accuracy: 46.66%\n",
      "Epoch [3/10], Step [750/2290], Loss: 1.3726, Accuracy: 46.81%\n",
      "Epoch [3/10], Step [800/2290], Loss: 1.4424, Accuracy: 46.68%\n",
      "Epoch [3/10], Step [850/2290], Loss: 1.8917, Accuracy: 46.71%\n",
      "Epoch [3/10], Step [900/2290], Loss: 1.6032, Accuracy: 46.78%\n",
      "Epoch [3/10], Step [950/2290], Loss: 1.6803, Accuracy: 46.80%\n",
      "Epoch [3/10], Step [1000/2290], Loss: 1.5785, Accuracy: 46.69%\n",
      "Epoch [3/10], Step [1050/2290], Loss: 1.5189, Accuracy: 46.63%\n",
      "Epoch [3/10], Step [1100/2290], Loss: 1.0816, Accuracy: 46.71%\n",
      "Epoch [3/10], Step [1150/2290], Loss: 1.3833, Accuracy: 46.66%\n",
      "Epoch [3/10], Step [1200/2290], Loss: 1.3724, Accuracy: 46.73%\n",
      "Epoch [3/10], Step [1250/2290], Loss: 1.8113, Accuracy: 46.74%\n",
      "Epoch [3/10], Step [1300/2290], Loss: 1.5432, Accuracy: 46.80%\n",
      "Epoch [3/10], Step [1350/2290], Loss: 1.4556, Accuracy: 46.82%\n",
      "Epoch [3/10], Step [1400/2290], Loss: 1.5297, Accuracy: 46.83%\n",
      "Epoch [3/10], Step [1450/2290], Loss: 1.5250, Accuracy: 46.88%\n",
      "Epoch [3/10], Step [1500/2290], Loss: 1.3228, Accuracy: 46.88%\n",
      "Epoch [3/10], Step [1550/2290], Loss: 1.5363, Accuracy: 46.85%\n",
      "Epoch [3/10], Step [1600/2290], Loss: 1.7046, Accuracy: 46.79%\n",
      "Epoch [3/10], Step [1650/2290], Loss: 1.4949, Accuracy: 46.79%\n",
      "Epoch [3/10], Step [1700/2290], Loss: 1.5834, Accuracy: 46.73%\n",
      "Epoch [3/10], Step [1750/2290], Loss: 1.5134, Accuracy: 46.81%\n",
      "Epoch [3/10], Step [1800/2290], Loss: 1.3017, Accuracy: 46.85%\n",
      "Epoch [3/10], Step [1850/2290], Loss: 1.3458, Accuracy: 46.90%\n",
      "Epoch [3/10], Step [1900/2290], Loss: 1.5327, Accuracy: 46.89%\n",
      "Epoch [3/10], Step [1950/2290], Loss: 1.5689, Accuracy: 46.96%\n",
      "Epoch [3/10], Step [2000/2290], Loss: 1.4295, Accuracy: 46.98%\n",
      "Epoch [3/10], Step [2050/2290], Loss: 1.6468, Accuracy: 47.02%\n",
      "Epoch [3/10], Step [2100/2290], Loss: 1.4131, Accuracy: 47.00%\n",
      "Epoch [3/10], Step [2150/2290], Loss: 1.7012, Accuracy: 47.00%\n",
      "Epoch [3/10], Step [2200/2290], Loss: 1.7170, Accuracy: 47.02%\n",
      "Epoch [3/10], Step [2250/2290], Loss: 1.4348, Accuracy: 47.02%\n",
      "Epoch [3/10] completed. Average Loss: 1.5270, Final Accuracy: 47.02%\n",
      "Epoch [4/10], Step [50/2290], Loss: 2.0016, Accuracy: 49.19%\n",
      "Epoch [4/10], Step [100/2290], Loss: 1.4129, Accuracy: 47.12%\n",
      "Epoch [4/10], Step [150/2290], Loss: 1.4065, Accuracy: 47.98%\n",
      "Epoch [4/10], Step [200/2290], Loss: 1.2062, Accuracy: 48.27%\n",
      "Epoch [4/10], Step [250/2290], Loss: 1.2183, Accuracy: 48.60%\n",
      "Epoch [4/10], Step [300/2290], Loss: 1.7910, Accuracy: 48.57%\n",
      "Epoch [4/10], Step [350/2290], Loss: 1.4434, Accuracy: 48.97%\n",
      "Epoch [4/10], Step [400/2290], Loss: 1.5975, Accuracy: 48.98%\n",
      "Epoch [4/10], Step [450/2290], Loss: 1.3292, Accuracy: 48.97%\n",
      "Epoch [4/10], Step [500/2290], Loss: 1.1746, Accuracy: 48.99%\n",
      "Epoch [4/10], Step [550/2290], Loss: 1.5005, Accuracy: 48.82%\n",
      "Epoch [4/10], Step [600/2290], Loss: 1.2723, Accuracy: 48.67%\n",
      "Epoch [4/10], Step [650/2290], Loss: 1.3066, Accuracy: 48.70%\n",
      "Epoch [4/10], Step [700/2290], Loss: 1.3836, Accuracy: 48.53%\n",
      "Epoch [4/10], Step [750/2290], Loss: 1.3504, Accuracy: 48.64%\n",
      "Epoch [4/10], Step [800/2290], Loss: 1.9390, Accuracy: 48.81%\n",
      "Epoch [4/10], Step [850/2290], Loss: 1.4480, Accuracy: 48.96%\n",
      "Epoch [4/10], Step [900/2290], Loss: 1.8186, Accuracy: 48.84%\n",
      "Epoch [4/10], Step [950/2290], Loss: 1.3055, Accuracy: 48.82%\n",
      "Epoch [4/10], Step [1000/2290], Loss: 1.4239, Accuracy: 48.79%\n",
      "Epoch [4/10], Step [1050/2290], Loss: 1.7268, Accuracy: 48.81%\n",
      "Epoch [4/10], Step [1100/2290], Loss: 1.5480, Accuracy: 48.81%\n",
      "Epoch [4/10], Step [1150/2290], Loss: 1.7014, Accuracy: 48.84%\n",
      "Epoch [4/10], Step [1200/2290], Loss: 1.5964, Accuracy: 48.78%\n",
      "Epoch [4/10], Step [1250/2290], Loss: 1.2869, Accuracy: 48.73%\n",
      "Epoch [4/10], Step [1300/2290], Loss: 1.8511, Accuracy: 48.66%\n",
      "Epoch [4/10], Step [1350/2290], Loss: 1.9385, Accuracy: 48.62%\n",
      "Epoch [4/10], Step [1400/2290], Loss: 1.4231, Accuracy: 48.55%\n",
      "Epoch [4/10], Step [1450/2290], Loss: 1.8338, Accuracy: 48.51%\n",
      "Epoch [4/10], Step [1500/2290], Loss: 1.8022, Accuracy: 48.55%\n",
      "Epoch [4/10], Step [1550/2290], Loss: 1.4026, Accuracy: 48.51%\n",
      "Epoch [4/10], Step [1600/2290], Loss: 1.2769, Accuracy: 48.54%\n",
      "Epoch [4/10], Step [1650/2290], Loss: 1.5124, Accuracy: 48.53%\n",
      "Epoch [4/10], Step [1700/2290], Loss: 1.5637, Accuracy: 48.53%\n",
      "Epoch [4/10], Step [1750/2290], Loss: 1.0615, Accuracy: 48.54%\n",
      "Epoch [4/10], Step [1800/2290], Loss: 1.8779, Accuracy: 48.51%\n",
      "Epoch [4/10], Step [1850/2290], Loss: 1.2837, Accuracy: 48.49%\n",
      "Epoch [4/10], Step [1900/2290], Loss: 1.3357, Accuracy: 48.47%\n",
      "Epoch [4/10], Step [1950/2290], Loss: 1.5681, Accuracy: 48.44%\n",
      "Epoch [4/10], Step [2000/2290], Loss: 1.3362, Accuracy: 48.40%\n",
      "Epoch [4/10], Step [2050/2290], Loss: 1.4543, Accuracy: 48.38%\n",
      "Epoch [4/10], Step [2100/2290], Loss: 1.3555, Accuracy: 48.38%\n",
      "Epoch [4/10], Step [2150/2290], Loss: 1.5733, Accuracy: 48.41%\n",
      "Epoch [4/10], Step [2200/2290], Loss: 1.4306, Accuracy: 48.41%\n",
      "Epoch [4/10], Step [2250/2290], Loss: 1.2481, Accuracy: 48.38%\n",
      "Epoch [4/10] completed. Average Loss: 1.4919, Final Accuracy: 48.38%\n",
      "Epoch [5/10], Step [50/2290], Loss: 1.4220, Accuracy: 51.06%\n",
      "Epoch [5/10], Step [100/2290], Loss: 1.2926, Accuracy: 50.38%\n",
      "Epoch [5/10], Step [150/2290], Loss: 1.4386, Accuracy: 50.29%\n",
      "Epoch [5/10], Step [200/2290], Loss: 1.7240, Accuracy: 49.48%\n",
      "Epoch [5/10], Step [250/2290], Loss: 1.5850, Accuracy: 49.56%\n",
      "Epoch [5/10], Step [300/2290], Loss: 1.3009, Accuracy: 49.58%\n",
      "Epoch [5/10], Step [350/2290], Loss: 1.8903, Accuracy: 49.85%\n",
      "Epoch [5/10], Step [400/2290], Loss: 1.3391, Accuracy: 49.73%\n",
      "Epoch [5/10], Step [450/2290], Loss: 1.3033, Accuracy: 50.06%\n",
      "Epoch [5/10], Step [500/2290], Loss: 1.2460, Accuracy: 50.23%\n",
      "Epoch [5/10], Step [550/2290], Loss: 1.5414, Accuracy: 50.13%\n",
      "Epoch [5/10], Step [600/2290], Loss: 1.4680, Accuracy: 49.98%\n",
      "Epoch [5/10], Step [650/2290], Loss: 1.3889, Accuracy: 50.00%\n",
      "Epoch [5/10], Step [700/2290], Loss: 1.4323, Accuracy: 49.90%\n",
      "Epoch [5/10], Step [750/2290], Loss: 1.5337, Accuracy: 49.84%\n",
      "Epoch [5/10], Step [800/2290], Loss: 1.2395, Accuracy: 49.95%\n",
      "Epoch [5/10], Step [850/2290], Loss: 1.4663, Accuracy: 49.89%\n",
      "Epoch [5/10], Step [900/2290], Loss: 1.3193, Accuracy: 49.89%\n",
      "Epoch [5/10], Step [950/2290], Loss: 1.4716, Accuracy: 49.78%\n",
      "Epoch [5/10], Step [1000/2290], Loss: 1.4260, Accuracy: 49.83%\n",
      "Epoch [5/10], Step [1050/2290], Loss: 1.2555, Accuracy: 49.82%\n",
      "Epoch [5/10], Step [1100/2290], Loss: 1.3261, Accuracy: 49.82%\n",
      "Epoch [5/10], Step [1150/2290], Loss: 1.4952, Accuracy: 49.83%\n",
      "Epoch [5/10], Step [1200/2290], Loss: 1.8999, Accuracy: 49.85%\n",
      "Epoch [5/10], Step [1250/2290], Loss: 1.6399, Accuracy: 49.84%\n",
      "Epoch [5/10], Step [1300/2290], Loss: 1.6200, Accuracy: 49.81%\n",
      "Epoch [5/10], Step [1350/2290], Loss: 1.6562, Accuracy: 49.83%\n",
      "Epoch [5/10], Step [1400/2290], Loss: 1.3455, Accuracy: 49.85%\n",
      "Epoch [5/10], Step [1450/2290], Loss: 1.4810, Accuracy: 49.83%\n",
      "Epoch [5/10], Step [1500/2290], Loss: 1.7641, Accuracy: 49.82%\n",
      "Epoch [5/10], Step [1550/2290], Loss: 1.5141, Accuracy: 49.76%\n",
      "Epoch [5/10], Step [1600/2290], Loss: 1.1851, Accuracy: 49.79%\n",
      "Epoch [5/10], Step [1650/2290], Loss: 1.8433, Accuracy: 49.72%\n",
      "Epoch [5/10], Step [1700/2290], Loss: 1.6130, Accuracy: 49.70%\n",
      "Epoch [5/10], Step [1750/2290], Loss: 1.4075, Accuracy: 49.65%\n",
      "Epoch [5/10], Step [1800/2290], Loss: 1.5128, Accuracy: 49.57%\n",
      "Epoch [5/10], Step [1850/2290], Loss: 1.1634, Accuracy: 49.58%\n",
      "Epoch [5/10], Step [1900/2290], Loss: 1.6947, Accuracy: 49.56%\n",
      "Epoch [5/10], Step [1950/2290], Loss: 1.7122, Accuracy: 49.52%\n",
      "Epoch [5/10], Step [2000/2290], Loss: 1.5406, Accuracy: 49.56%\n",
      "Epoch [5/10], Step [2050/2290], Loss: 1.3093, Accuracy: 49.53%\n",
      "Epoch [5/10], Step [2100/2290], Loss: 1.4640, Accuracy: 49.58%\n",
      "Epoch [5/10], Step [2150/2290], Loss: 1.5217, Accuracy: 49.54%\n",
      "Epoch [5/10], Step [2200/2290], Loss: 1.5721, Accuracy: 49.51%\n",
      "Epoch [5/10], Step [2250/2290], Loss: 1.5897, Accuracy: 49.46%\n",
      "Epoch [5/10] completed. Average Loss: 1.4631, Final Accuracy: 49.48%\n",
      "Epoch [6/10], Step [50/2290], Loss: 1.0605, Accuracy: 50.81%\n",
      "Epoch [6/10], Step [100/2290], Loss: 1.3918, Accuracy: 51.34%\n",
      "Epoch [6/10], Step [150/2290], Loss: 1.0166, Accuracy: 52.08%\n",
      "Epoch [6/10], Step [200/2290], Loss: 1.5741, Accuracy: 52.02%\n",
      "Epoch [6/10], Step [250/2290], Loss: 1.6281, Accuracy: 51.27%\n",
      "Epoch [6/10], Step [300/2290], Loss: 1.6252, Accuracy: 50.84%\n",
      "Epoch [6/10], Step [350/2290], Loss: 1.5379, Accuracy: 50.93%\n",
      "Epoch [6/10], Step [400/2290], Loss: 1.3624, Accuracy: 50.69%\n",
      "Epoch [6/10], Step [450/2290], Loss: 1.6968, Accuracy: 50.65%\n",
      "Epoch [6/10], Step [500/2290], Loss: 1.3179, Accuracy: 50.49%\n",
      "Epoch [6/10], Step [550/2290], Loss: 1.3061, Accuracy: 50.48%\n",
      "Epoch [6/10], Step [600/2290], Loss: 1.2998, Accuracy: 50.39%\n",
      "Epoch [6/10], Step [650/2290], Loss: 1.8932, Accuracy: 50.51%\n",
      "Epoch [6/10], Step [700/2290], Loss: 1.4987, Accuracy: 50.57%\n",
      "Epoch [6/10], Step [750/2290], Loss: 1.6525, Accuracy: 50.53%\n",
      "Epoch [6/10], Step [800/2290], Loss: 1.2881, Accuracy: 50.60%\n",
      "Epoch [6/10], Step [850/2290], Loss: 1.4602, Accuracy: 50.68%\n",
      "Epoch [6/10], Step [900/2290], Loss: 1.2023, Accuracy: 50.68%\n",
      "Epoch [6/10], Step [950/2290], Loss: 1.7475, Accuracy: 50.71%\n",
      "Epoch [6/10], Step [1000/2290], Loss: 1.3120, Accuracy: 50.70%\n",
      "Epoch [6/10], Step [1050/2290], Loss: 1.5996, Accuracy: 50.68%\n",
      "Epoch [6/10], Step [1100/2290], Loss: 1.3882, Accuracy: 50.60%\n",
      "Epoch [6/10], Step [1150/2290], Loss: 1.5052, Accuracy: 50.56%\n",
      "Epoch [6/10], Step [1200/2290], Loss: 1.8557, Accuracy: 50.57%\n",
      "Epoch [6/10], Step [1250/2290], Loss: 1.3712, Accuracy: 50.55%\n",
      "Epoch [6/10], Step [1300/2290], Loss: 0.9276, Accuracy: 50.55%\n",
      "Epoch [6/10], Step [1350/2290], Loss: 1.7027, Accuracy: 50.40%\n",
      "Epoch [6/10], Step [1400/2290], Loss: 1.4539, Accuracy: 50.31%\n",
      "Epoch [6/10], Step [1450/2290], Loss: 1.4882, Accuracy: 50.29%\n",
      "Epoch [6/10], Step [1500/2290], Loss: 1.4236, Accuracy: 50.30%\n",
      "Epoch [6/10], Step [1550/2290], Loss: 1.3115, Accuracy: 50.31%\n",
      "Epoch [6/10], Step [1600/2290], Loss: 1.5183, Accuracy: 50.33%\n",
      "Epoch [6/10], Step [1650/2290], Loss: 1.3065, Accuracy: 50.28%\n",
      "Epoch [6/10], Step [1700/2290], Loss: 1.3102, Accuracy: 50.33%\n",
      "Epoch [6/10], Step [1750/2290], Loss: 1.6703, Accuracy: 50.22%\n",
      "Epoch [6/10], Step [1800/2290], Loss: 1.2779, Accuracy: 50.24%\n",
      "Epoch [6/10], Step [1850/2290], Loss: 1.2548, Accuracy: 50.24%\n",
      "Epoch [6/10], Step [1900/2290], Loss: 1.1721, Accuracy: 50.21%\n",
      "Epoch [6/10], Step [1950/2290], Loss: 1.3043, Accuracy: 50.19%\n",
      "Epoch [6/10], Step [2000/2290], Loss: 1.2825, Accuracy: 50.18%\n",
      "Epoch [6/10], Step [2050/2290], Loss: 1.5684, Accuracy: 50.17%\n",
      "Epoch [6/10], Step [2100/2290], Loss: 1.3527, Accuracy: 50.14%\n",
      "Epoch [6/10], Step [2150/2290], Loss: 1.3580, Accuracy: 50.14%\n",
      "Epoch [6/10], Step [2200/2290], Loss: 1.6552, Accuracy: 50.13%\n",
      "Epoch [6/10], Step [2250/2290], Loss: 1.6722, Accuracy: 50.11%\n",
      "Epoch [6/10] completed. Average Loss: 1.4408, Final Accuracy: 50.08%\n",
      "Epoch [7/10], Step [50/2290], Loss: 1.7001, Accuracy: 51.50%\n",
      "Epoch [7/10], Step [100/2290], Loss: 1.7258, Accuracy: 52.09%\n",
      "Epoch [7/10], Step [150/2290], Loss: 1.5350, Accuracy: 51.56%\n",
      "Epoch [7/10], Step [200/2290], Loss: 1.5287, Accuracy: 51.20%\n",
      "Epoch [7/10], Step [250/2290], Loss: 1.1118, Accuracy: 51.59%\n",
      "Epoch [7/10], Step [300/2290], Loss: 1.3894, Accuracy: 51.76%\n",
      "Epoch [7/10], Step [350/2290], Loss: 1.5362, Accuracy: 51.59%\n",
      "Epoch [7/10], Step [400/2290], Loss: 1.1886, Accuracy: 51.17%\n",
      "Epoch [7/10], Step [450/2290], Loss: 1.5272, Accuracy: 51.13%\n",
      "Epoch [7/10], Step [500/2290], Loss: 1.4651, Accuracy: 51.06%\n",
      "Epoch [7/10], Step [550/2290], Loss: 1.2420, Accuracy: 51.02%\n",
      "Epoch [7/10], Step [600/2290], Loss: 1.5820, Accuracy: 50.99%\n",
      "Epoch [7/10], Step [650/2290], Loss: 1.2960, Accuracy: 50.94%\n",
      "Epoch [7/10], Step [700/2290], Loss: 1.8583, Accuracy: 50.83%\n",
      "Epoch [7/10], Step [750/2290], Loss: 1.3698, Accuracy: 50.90%\n",
      "Epoch [7/10], Step [800/2290], Loss: 1.2082, Accuracy: 50.89%\n",
      "Epoch [7/10], Step [850/2290], Loss: 1.5645, Accuracy: 50.75%\n",
      "Epoch [7/10], Step [900/2290], Loss: 1.5742, Accuracy: 50.66%\n",
      "Epoch [7/10], Step [950/2290], Loss: 1.8039, Accuracy: 50.75%\n",
      "Epoch [7/10], Step [1000/2290], Loss: 1.3582, Accuracy: 50.86%\n",
      "Epoch [7/10], Step [1050/2290], Loss: 1.3154, Accuracy: 50.86%\n",
      "Epoch [7/10], Step [1100/2290], Loss: 1.2349, Accuracy: 50.91%\n",
      "Epoch [7/10], Step [1150/2290], Loss: 1.2916, Accuracy: 50.93%\n",
      "Epoch [7/10], Step [1200/2290], Loss: 1.2950, Accuracy: 50.92%\n",
      "Epoch [7/10], Step [1250/2290], Loss: 1.1362, Accuracy: 50.94%\n",
      "Epoch [7/10], Step [1300/2290], Loss: 1.4797, Accuracy: 50.93%\n",
      "Epoch [7/10], Step [1350/2290], Loss: 1.4638, Accuracy: 50.92%\n",
      "Epoch [7/10], Step [1400/2290], Loss: 1.8310, Accuracy: 50.95%\n",
      "Epoch [7/10], Step [1450/2290], Loss: 1.1303, Accuracy: 50.95%\n",
      "Epoch [7/10], Step [1500/2290], Loss: 1.6956, Accuracy: 50.87%\n",
      "Epoch [7/10], Step [1550/2290], Loss: 1.5349, Accuracy: 50.93%\n",
      "Epoch [7/10], Step [1600/2290], Loss: 1.5262, Accuracy: 50.93%\n",
      "Epoch [7/10], Step [1650/2290], Loss: 1.6702, Accuracy: 50.91%\n",
      "Epoch [7/10], Step [1700/2290], Loss: 1.5565, Accuracy: 50.91%\n",
      "Epoch [7/10], Step [1750/2290], Loss: 1.4020, Accuracy: 50.89%\n",
      "Epoch [7/10], Step [1800/2290], Loss: 1.3293, Accuracy: 50.88%\n",
      "Epoch [7/10], Step [1850/2290], Loss: 1.5123, Accuracy: 50.85%\n",
      "Epoch [7/10], Step [1900/2290], Loss: 1.6624, Accuracy: 50.82%\n",
      "Epoch [7/10], Step [1950/2290], Loss: 1.3707, Accuracy: 50.84%\n",
      "Epoch [7/10], Step [2000/2290], Loss: 0.9297, Accuracy: 50.86%\n",
      "Epoch [7/10], Step [2050/2290], Loss: 1.3537, Accuracy: 50.88%\n",
      "Epoch [7/10], Step [2100/2290], Loss: 1.7040, Accuracy: 50.91%\n",
      "Epoch [7/10], Step [2150/2290], Loss: 1.1734, Accuracy: 50.90%\n",
      "Epoch [7/10], Step [2200/2290], Loss: 1.7816, Accuracy: 50.87%\n",
      "Epoch [7/10], Step [2250/2290], Loss: 1.7919, Accuracy: 50.84%\n",
      "Epoch [7/10] completed. Average Loss: 1.4188, Final Accuracy: 50.82%\n",
      "Epoch [8/10], Step [50/2290], Loss: 1.6618, Accuracy: 53.44%\n",
      "Epoch [8/10], Step [100/2290], Loss: 1.2355, Accuracy: 52.28%\n",
      "Epoch [8/10], Step [150/2290], Loss: 1.3743, Accuracy: 51.83%\n",
      "Epoch [8/10], Step [200/2290], Loss: 1.5389, Accuracy: 51.45%\n",
      "Epoch [8/10], Step [250/2290], Loss: 1.6397, Accuracy: 51.52%\n",
      "Epoch [8/10], Step [300/2290], Loss: 1.1846, Accuracy: 51.49%\n",
      "Epoch [8/10], Step [350/2290], Loss: 1.7314, Accuracy: 51.68%\n",
      "Epoch [8/10], Step [400/2290], Loss: 1.3631, Accuracy: 51.57%\n",
      "Epoch [8/10], Step [450/2290], Loss: 1.1650, Accuracy: 51.60%\n",
      "Epoch [8/10], Step [500/2290], Loss: 1.3324, Accuracy: 51.95%\n",
      "Epoch [8/10], Step [550/2290], Loss: 1.3254, Accuracy: 51.98%\n",
      "Epoch [8/10], Step [600/2290], Loss: 1.3449, Accuracy: 52.10%\n",
      "Epoch [8/10], Step [650/2290], Loss: 1.1567, Accuracy: 52.30%\n",
      "Epoch [8/10], Step [700/2290], Loss: 1.0499, Accuracy: 52.20%\n",
      "Epoch [8/10], Step [750/2290], Loss: 1.3142, Accuracy: 52.23%\n",
      "Epoch [8/10], Step [800/2290], Loss: 1.5702, Accuracy: 52.26%\n",
      "Epoch [8/10], Step [850/2290], Loss: 0.9684, Accuracy: 52.23%\n",
      "Epoch [8/10], Step [900/2290], Loss: 1.0809, Accuracy: 52.09%\n",
      "Epoch [8/10], Step [950/2290], Loss: 1.5973, Accuracy: 52.00%\n",
      "Epoch [8/10], Step [1000/2290], Loss: 1.5800, Accuracy: 51.95%\n",
      "Epoch [8/10], Step [1050/2290], Loss: 1.7432, Accuracy: 52.05%\n",
      "Epoch [8/10], Step [1100/2290], Loss: 1.1968, Accuracy: 51.97%\n",
      "Epoch [8/10], Step [1150/2290], Loss: 1.5448, Accuracy: 51.93%\n",
      "Epoch [8/10], Step [1200/2290], Loss: 1.3775, Accuracy: 51.89%\n",
      "Epoch [8/10], Step [1250/2290], Loss: 1.2195, Accuracy: 51.85%\n",
      "Epoch [8/10], Step [1300/2290], Loss: 1.4605, Accuracy: 51.84%\n",
      "Epoch [8/10], Step [1350/2290], Loss: 1.0878, Accuracy: 51.78%\n",
      "Epoch [8/10], Step [1400/2290], Loss: 1.1079, Accuracy: 51.70%\n",
      "Epoch [8/10], Step [1450/2290], Loss: 1.4839, Accuracy: 51.75%\n",
      "Epoch [8/10], Step [1500/2290], Loss: 1.2687, Accuracy: 51.67%\n",
      "Epoch [8/10], Step [1550/2290], Loss: 1.8126, Accuracy: 51.57%\n",
      "Epoch [8/10], Step [1600/2290], Loss: 1.2288, Accuracy: 51.55%\n",
      "Epoch [8/10], Step [1650/2290], Loss: 1.6496, Accuracy: 51.55%\n",
      "Epoch [8/10], Step [1700/2290], Loss: 1.7409, Accuracy: 51.59%\n",
      "Epoch [8/10], Step [1750/2290], Loss: 1.4049, Accuracy: 51.59%\n",
      "Epoch [8/10], Step [1800/2290], Loss: 1.3145, Accuracy: 51.59%\n",
      "Epoch [8/10], Step [1850/2290], Loss: 1.4129, Accuracy: 51.59%\n",
      "Epoch [8/10], Step [1900/2290], Loss: 1.4561, Accuracy: 51.60%\n",
      "Epoch [8/10], Step [1950/2290], Loss: 1.3571, Accuracy: 51.57%\n",
      "Epoch [8/10], Step [2000/2290], Loss: 1.4233, Accuracy: 51.53%\n",
      "Epoch [8/10], Step [2050/2290], Loss: 1.3412, Accuracy: 51.48%\n",
      "Epoch [8/10], Step [2100/2290], Loss: 1.7749, Accuracy: 51.45%\n",
      "Epoch [8/10], Step [2150/2290], Loss: 1.3539, Accuracy: 51.49%\n",
      "Epoch [8/10], Step [2200/2290], Loss: 1.1773, Accuracy: 51.48%\n",
      "Epoch [8/10], Step [2250/2290], Loss: 1.2817, Accuracy: 51.44%\n",
      "Epoch [8/10] completed. Average Loss: 1.4078, Final Accuracy: 51.42%\n",
      "Epoch [9/10], Step [50/2290], Loss: 1.2883, Accuracy: 50.06%\n",
      "Epoch [9/10], Step [100/2290], Loss: 1.3213, Accuracy: 52.19%\n",
      "Epoch [9/10], Step [150/2290], Loss: 1.3401, Accuracy: 52.77%\n",
      "Epoch [9/10], Step [200/2290], Loss: 1.3477, Accuracy: 52.52%\n",
      "Epoch [9/10], Step [250/2290], Loss: 1.1942, Accuracy: 52.59%\n",
      "Epoch [9/10], Step [300/2290], Loss: 1.1063, Accuracy: 52.55%\n",
      "Epoch [9/10], Step [350/2290], Loss: 1.1623, Accuracy: 52.54%\n",
      "Epoch [9/10], Step [400/2290], Loss: 1.2094, Accuracy: 52.63%\n",
      "Epoch [9/10], Step [450/2290], Loss: 1.5634, Accuracy: 52.56%\n",
      "Epoch [9/10], Step [500/2290], Loss: 1.5836, Accuracy: 52.44%\n",
      "Epoch [9/10], Step [550/2290], Loss: 1.5016, Accuracy: 52.44%\n",
      "Epoch [9/10], Step [600/2290], Loss: 1.1475, Accuracy: 52.51%\n",
      "Epoch [9/10], Step [650/2290], Loss: 1.3056, Accuracy: 52.54%\n",
      "Epoch [9/10], Step [700/2290], Loss: 1.1965, Accuracy: 52.42%\n",
      "Epoch [9/10], Step [750/2290], Loss: 1.4149, Accuracy: 52.42%\n",
      "Epoch [9/10], Step [800/2290], Loss: 1.2920, Accuracy: 52.46%\n",
      "Epoch [9/10], Step [850/2290], Loss: 1.5217, Accuracy: 52.33%\n",
      "Epoch [9/10], Step [900/2290], Loss: 1.3640, Accuracy: 52.30%\n",
      "Epoch [9/10], Step [950/2290], Loss: 1.4819, Accuracy: 52.25%\n",
      "Epoch [9/10], Step [1000/2290], Loss: 1.6317, Accuracy: 52.22%\n",
      "Epoch [9/10], Step [1050/2290], Loss: 1.1658, Accuracy: 52.22%\n",
      "Epoch [9/10], Step [1100/2290], Loss: 1.2673, Accuracy: 52.17%\n",
      "Epoch [9/10], Step [1150/2290], Loss: 1.0147, Accuracy: 52.24%\n",
      "Epoch [9/10], Step [1200/2290], Loss: 1.4846, Accuracy: 52.19%\n",
      "Epoch [9/10], Step [1250/2290], Loss: 1.1795, Accuracy: 52.20%\n",
      "Epoch [9/10], Step [1300/2290], Loss: 1.5508, Accuracy: 52.26%\n",
      "Epoch [9/10], Step [1350/2290], Loss: 1.5145, Accuracy: 52.20%\n",
      "Epoch [9/10], Step [1400/2290], Loss: 1.1407, Accuracy: 52.19%\n",
      "Epoch [9/10], Step [1450/2290], Loss: 1.6426, Accuracy: 52.26%\n",
      "Epoch [9/10], Step [1500/2290], Loss: 1.5976, Accuracy: 52.23%\n",
      "Epoch [9/10], Step [1550/2290], Loss: 1.2312, Accuracy: 52.23%\n",
      "Epoch [9/10], Step [1600/2290], Loss: 1.5935, Accuracy: 52.20%\n",
      "Epoch [9/10], Step [1650/2290], Loss: 1.3737, Accuracy: 52.24%\n",
      "Epoch [9/10], Step [1700/2290], Loss: 1.1828, Accuracy: 52.23%\n",
      "Epoch [9/10], Step [1750/2290], Loss: 1.3286, Accuracy: 52.24%\n",
      "Epoch [9/10], Step [1800/2290], Loss: 1.0649, Accuracy: 52.27%\n",
      "Epoch [9/10], Step [1850/2290], Loss: 1.4493, Accuracy: 52.24%\n",
      "Epoch [9/10], Step [1900/2290], Loss: 1.4283, Accuracy: 52.24%\n",
      "Epoch [9/10], Step [1950/2290], Loss: 1.3860, Accuracy: 52.15%\n",
      "Epoch [9/10], Step [2000/2290], Loss: 1.4619, Accuracy: 52.10%\n",
      "Epoch [9/10], Step [2050/2290], Loss: 1.2663, Accuracy: 52.06%\n",
      "Epoch [9/10], Step [2100/2290], Loss: 1.1295, Accuracy: 52.06%\n",
      "Epoch [9/10], Step [2150/2290], Loss: 1.4625, Accuracy: 52.04%\n",
      "Epoch [9/10], Step [2200/2290], Loss: 1.3523, Accuracy: 52.02%\n",
      "Epoch [9/10], Step [2250/2290], Loss: 1.4020, Accuracy: 51.95%\n",
      "Epoch [9/10] completed. Average Loss: 1.3922, Final Accuracy: 51.95%\n",
      "Epoch [10/10], Step [50/2290], Loss: 1.2922, Accuracy: 51.50%\n",
      "Epoch [10/10], Step [100/2290], Loss: 1.4392, Accuracy: 53.50%\n",
      "Epoch [10/10], Step [150/2290], Loss: 1.3889, Accuracy: 53.29%\n",
      "Epoch [10/10], Step [200/2290], Loss: 1.5103, Accuracy: 53.31%\n",
      "Epoch [10/10], Step [250/2290], Loss: 1.1294, Accuracy: 53.40%\n",
      "Epoch [10/10], Step [300/2290], Loss: 1.7051, Accuracy: 53.11%\n",
      "Epoch [10/10], Step [350/2290], Loss: 1.4991, Accuracy: 52.84%\n",
      "Epoch [10/10], Step [400/2290], Loss: 1.6524, Accuracy: 52.55%\n",
      "Epoch [10/10], Step [450/2290], Loss: 1.2809, Accuracy: 52.47%\n",
      "Epoch [10/10], Step [500/2290], Loss: 1.3183, Accuracy: 52.48%\n",
      "Epoch [10/10], Step [550/2290], Loss: 1.2870, Accuracy: 52.45%\n",
      "Epoch [10/10], Step [600/2290], Loss: 1.2681, Accuracy: 52.49%\n",
      "Epoch [10/10], Step [650/2290], Loss: 1.3266, Accuracy: 52.52%\n",
      "Epoch [10/10], Step [700/2290], Loss: 1.3220, Accuracy: 52.48%\n",
      "Epoch [10/10], Step [750/2290], Loss: 1.3627, Accuracy: 52.44%\n",
      "Epoch [10/10], Step [800/2290], Loss: 1.2898, Accuracy: 52.40%\n",
      "Epoch [10/10], Step [850/2290], Loss: 1.0534, Accuracy: 52.48%\n",
      "Epoch [10/10], Step [900/2290], Loss: 1.3850, Accuracy: 52.57%\n",
      "Epoch [10/10], Step [950/2290], Loss: 1.4939, Accuracy: 52.63%\n",
      "Epoch [10/10], Step [1000/2290], Loss: 1.4823, Accuracy: 52.60%\n",
      "Epoch [10/10], Step [1050/2290], Loss: 1.3141, Accuracy: 52.68%\n",
      "Epoch [10/10], Step [1100/2290], Loss: 1.4682, Accuracy: 52.68%\n",
      "Epoch [10/10], Step [1150/2290], Loss: 1.1600, Accuracy: 52.72%\n",
      "Epoch [10/10], Step [1200/2290], Loss: 1.3651, Accuracy: 52.71%\n",
      "Epoch [10/10], Step [1250/2290], Loss: 1.3210, Accuracy: 52.69%\n",
      "Epoch [10/10], Step [1300/2290], Loss: 1.0733, Accuracy: 52.64%\n",
      "Epoch [10/10], Step [1350/2290], Loss: 1.3871, Accuracy: 52.65%\n",
      "Epoch [10/10], Step [1400/2290], Loss: 1.4342, Accuracy: 52.70%\n",
      "Epoch [10/10], Step [1450/2290], Loss: 1.0061, Accuracy: 52.63%\n",
      "Epoch [10/10], Step [1500/2290], Loss: 1.7618, Accuracy: 52.62%\n",
      "Epoch [10/10], Step [1550/2290], Loss: 1.6568, Accuracy: 52.61%\n",
      "Epoch [10/10], Step [1600/2290], Loss: 1.1921, Accuracy: 52.66%\n",
      "Epoch [10/10], Step [1650/2290], Loss: 1.3225, Accuracy: 52.64%\n",
      "Epoch [10/10], Step [1700/2290], Loss: 1.3983, Accuracy: 52.60%\n",
      "Epoch [10/10], Step [1750/2290], Loss: 1.0314, Accuracy: 52.58%\n",
      "Epoch [10/10], Step [1800/2290], Loss: 1.3976, Accuracy: 52.53%\n",
      "Epoch [10/10], Step [1850/2290], Loss: 1.2325, Accuracy: 52.55%\n",
      "Epoch [10/10], Step [1900/2290], Loss: 1.1805, Accuracy: 52.51%\n",
      "Epoch [10/10], Step [1950/2290], Loss: 1.1733, Accuracy: 52.50%\n",
      "Epoch [10/10], Step [2000/2290], Loss: 1.3077, Accuracy: 52.52%\n",
      "Epoch [10/10], Step [2050/2290], Loss: 1.5375, Accuracy: 52.53%\n",
      "Epoch [10/10], Step [2100/2290], Loss: 1.5256, Accuracy: 52.51%\n",
      "Epoch [10/10], Step [2150/2290], Loss: 1.3458, Accuracy: 52.47%\n",
      "Epoch [10/10], Step [2200/2290], Loss: 1.3472, Accuracy: 52.45%\n",
      "Epoch [10/10], Step [2250/2290], Loss: 1.1348, Accuracy: 52.46%\n",
      "Epoch [10/10] completed. Average Loss: 1.3758, Final Accuracy: 52.40%\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba9681f3-2f52-4274-9cc0-1b414c33195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model on test set...\n",
      "Test Accuracy: 53.28%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bbb74-a083-4dce-be51-0e7accf48d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tf GPU",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
